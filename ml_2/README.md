ЛР №2. Обнаружение спама/мошеннических СМС

Вариант 48: Анализ пар слов / TF-IDF / sklearn* / ROC


 Контрольные вопросы:
 1. Что такое стоп-слова при обработке текста.
 
 Часто встречающиеся слова, артикли, междометия и т.д., не несут никакой пользы, лишь создают шумы.
 
![Alt-текст](https://miro.medium.com/max/720/1*R1NmayfziRv8QKKUw4dt_w.png)

 2.	Что такое токенизация при обработке текста.
 
 Процесс разделения текста на компоненты - токены (предложения или слова).
 
 3.	Что такое нормализация при обработке текста.
 
 Процесс приведения токенов к единому виду для избавления от поверхностной разницы в написании (лемматизация и стемминг).
 
 4. Что такое стемминг.
 
 Грубый эвритстический процесс, который выделяет корень слова (лемма) и отрезает все лишнее. Приводит к потере словообразовательных суффиксов, а также не учитывает, что некоторые слова могут являться леммой для непохожих по написанию (good -> better). Работает быстрее.
 
 «Caring» -> Стемминг -> «Car»
 
 5. Что такое лемматизация.
 
 Нормализация, использующая словарь и морфологический анализ, чтобы привести слово к канонической форме – лемма. Работает дольше.
 
 Разница между стемминг (stemming) и лемматизацией заключается в том, что лемматизация учитывает контекст и преобразует слово в его значимую базовую форму, тогда как стемминг просто удаляет последние несколько символов, что часто приводит к неверному значению и орфографическим ошибкам.

Например, лемматизация правильно определила бы базовую форму «caring» и «care», в то время как стемминг отрезал бы «ing» и преобразовал ее в car.

«Caring» -> Лемматизация -> «Care»
 
 6,7,8.	Способы представления текста (Boolean Model, Bag of Words).
 
 Для работы алгоритмов машинного обучения необходимо преобразовать текст в числовые характеристики (извлечь признаки). Boolean Model: характеризует наличие или отсутствие токена в документе. Bag of Words: документ характеризуется вектором встречаемости словарных слов в документе (подсчитывается количество вхождений).
 
 9. Что такое TF-IDF.
 
 (Term frequency – Inverse document frequency). Мера оценки важности слова в документе, являющегося частью коллекции документов. Снижается оценка слова, которое часто встречается во всех документах коллекции.
 
 ```
 tf-idf = tf * idf
 ```
 где,

* tf - частота слова x. Сколько раз слово встретилось в документе делить на количество слов в документе,

* idf - обратная частота документа.

```
idf = log(N/df)

N - всего документов в коллекции.
df - документов в коллекции, в которых встречается данное слово.
```

Чтобы избежать деление на ноль используем это:

![Alt-текст](https://miro.medium.com/max/720/1*8TT1FmB6Kvl5PoDvozbWtQ.png)

 Учёт idf уменьшает вес широкоупотребительных слов.
 
