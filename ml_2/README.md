ЛР №2. Обнаружение спама/мошеннических СМС

Вариант 48: Анализ пар слов / TF-IDF / sklearn* / ROC


ROC

Полное название ROC — Receiver Operating Characteristic (рабочая характеристика приёмника).

Метрики TPR и FPR

True Positive Rate (TPR) показывает, какой процент среди всех positive верно предсказан моделью.
TPR = TP / (TP + FN).

False Positive Rate (FPR): какой процент среди всех negative неверно предсказан моделью.
FPR = FP / (FP + TN).

ROC — это просто отношение TPR к FPR.

![Alt-текст](https://pythonru.com/wp-content/uploads/2021/04/roc-krivaya.png)

Посмотрите на две точки на ROC-кривой. Зеленая точка имеет очень высокий порог, это означает, что только если вы уверены на 99%, можете классифицировать случай как positive. Красная точка имеет относительно более низкий порог. Это означает, что вы можете классифицировать случай как positive, если вы уверены на 90%.


 Контрольные вопросы:
 1. Что такое стоп-слова при обработке текста.
 
 Часто встречающиеся слова, артикли, междометия и т.д., не несут никакой пользы, лишь создают шумы.
 
![Alt-текст](https://miro.medium.com/max/720/1*R1NmayfziRv8QKKUw4dt_w.png)

 2.	Что такое токенизация при обработке текста.
 
 Процесс разделения текста на компоненты - токены (предложения или слова).
 
 3.	Что такое нормализация при обработке текста.
 
 Процесс приведения токенов к единому виду для избавления от поверхностной разницы в написании (лемматизация и стемминг).
 
 4. Что такое стемминг.
 
 Грубый эвритстический процесс, который выделяет корень слова (лемма) и отрезает все лишнее. Приводит к потере словообразовательных суффиксов, а также не учитывает, что некоторые слова могут являться леммой для непохожих по написанию (good -> better). Работает быстрее.
 
 «Caring» -> Стемминг -> «Car»
 
 5. Что такое лемматизация.
 
 Нормализация, использующая словарь и морфологический анализ, чтобы привести слово к канонической форме – лемма. Работает дольше.
 
 Разница между стемминг (stemming) и лемматизацией заключается в том, что лемматизация учитывает контекст и преобразует слово в его значимую базовую форму, тогда как стемминг просто удаляет последние несколько символов, что часто приводит к неверному значению и орфографическим ошибкам.

Например, лемматизация правильно определила бы базовую форму «caring» и «care», в то время как стемминг отрезал бы «ing» и преобразовал ее в car.

«Caring» -> Лемматизация -> «Care»
 
 6,7,8.	Способы представления текста (Boolean Model, Bag of Words).
 
 Для работы алгоритмов машинного обучения необходимо преобразовать текст в числовые характеристики (извлечь признаки). Boolean Model: характеризует наличие или отсутствие токена в документе. 
 
 Bag of Words: документ характеризуется вектором встречаемости словарных слов в документе (подсчитывается количество вхождений).  Bag of Words помогает преобразовать текст в числовое представление (векторы числовых признаков), чтобы его можно было использовать для обучения моделей с использованием алгоритмов машинного обучения
 
 9. Что такое TF-IDF.
 
 (Term frequency – Inverse document frequency). Мера оценки важности слова в документе, являющегося частью коллекции документов. Снижается оценка слова, которое часто встречается во всех документах коллекции.
 
 ```
 tf-idf = tf * idf
 ```
 где,

* tf - частота слова x. Сколько раз слово встретилось в документе делить на количество слов в документе,

* idf - обратная частота документа.

```
idf = log(N/df)

N - всего документов в коллекции.
df - документов в коллекции, в которых встречается данное слово.
```

Чтобы избежать деление на ноль используем это:

![Alt-текст](https://miro.medium.com/max/720/1*8TT1FmB6Kvl5PoDvozbWtQ.png)

 Учёт idf уменьшает вес широкоупотребительных слов.
 
